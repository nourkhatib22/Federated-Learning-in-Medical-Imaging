{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVzox1NpItSg",
        "outputId": "50a0cf45-715b-4daa-d059-306c9570dcf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/EECE608"
      ],
      "metadata": {
        "id": "obyezN_UIv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = \"/content/drive/MyDrive/EECE608/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "valid_data = \"/content/drive/MyDrive/EECE608/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/\""
      ],
      "metadata": {
        "id": "a6j5vgnmIxT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jbAcnkLIybq",
        "outputId": "a1e51be9-3a3e-461a-bc65-6d867cda8a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.24.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nilearn\n",
        "! pip install keras_unet_collection\n",
        "!pip install torch torchvision\n",
        "!pip install -q monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2o274bLIzuS",
        "outputId": "36666ccf-340c-4077-b56f-89f5b0bd7723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.11/dist-packages (0.11.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.3.1)\n",
            "Requirement already satisfied: nibabel>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.24.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nilearn) (24.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from nilearn) (1.14.1)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel>=5.2.0->nilearn) (6.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel>=5.2.0->nilearn) (4.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->nilearn) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->nilearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n",
            "Requirement already satisfied: keras_unet_collection in /usr/local/lib/python3.11/dist-packages (0.1.13)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.24.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "TsjlNcSZQl3n",
        "outputId": "18539fbe-9870-463a-c35c-e626573cb875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "7024d7c460cd4497a54e9fa1c35bbd38"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, gc, copy\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from opacus import PrivacyEngine"
      ],
      "metadata": {
        "id": "7xrqyySplOoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ε = 8 (epsilon)\n",
        "IMG_SIZE = 64\n",
        "VOLUME_SLICES = 3\n",
        "VOLUME_START_AT = 22\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "ROUNDS = 1\n",
        "LR = 5e-4\n",
        "NOISE_MULTIPLIER = 1.3\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "train_data = \"/content/drive/MyDrive/EECE608/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BraTSDataset(Dataset):\n",
        "    def __init__(self, list_ids, modality):\n",
        "        self.list_ids = list_ids\n",
        "        self.modality = modality\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_ids) * VOLUME_SLICES\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        case_idx = idx // VOLUME_SLICES\n",
        "        slice_idx = VOLUME_START_AT + (idx % VOLUME_SLICES)\n",
        "        case_id = self.list_ids[case_idx]\n",
        "        case_path = os.path.join(train_data, case_id)\n",
        "\n",
        "        img = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_{self.modality}.nii\")).dataobj[:, :, slice_idx], dtype=np.float32)\n",
        "        seg = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_seg.nii\")).dataobj[:, :, slice_idx], dtype=np.uint8)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        seg = cv2.resize(seg, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img / (np.max(img) + 1e-8)\n",
        "        seg[seg == 4] = 3\n",
        "\n",
        "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(seg, dtype=torch.long)\n",
        "\n",
        "class ResNetLite(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), nn.GroupNorm(4, 16), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.GroupNorm(4, 32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.GroupNorm(4, 64), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, 4, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def dice_score(preds, targets, smooth=1e-6):\n",
        "    preds = torch.argmax(preds, dim=1).view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (preds == targets).float().sum()\n",
        "    return (2. * intersection + smooth) / (preds.numel() + targets.numel() + smooth)\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            if out.shape[-2:] != y.shape[-2:]:\n",
        "                out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            score += dice_score(out, y).item()\n",
        "    return score / len(dataloader)\n",
        "def train_dp(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        if out.shape[-2:] != y.shape[-2:]:\n",
        "            out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "def create_clients(ids, modalities=['flair', 't1ce', 't2']):\n",
        "    size = len(ids) // len(modalities)\n",
        "    shards = [ids[i * size:(i + 1) * size] for i in range(len(modalities))]\n",
        "    return {f\"client_{i+1}\": (shards[i], modalities[i]) for i in range(len(modalities))}\n",
        "print(\"\\n Begin FL + DP using ResNetLite\")\n",
        "\n",
        "\n",
        "dirs = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "dirs.remove(train_data + 'BraTS20_Training_355')\n",
        "ids = [os.path.basename(p) for p in dirs]\n",
        "train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "\n",
        "clients = create_clients(train_ids[:6])\n",
        "val_ds = BraTSDataset(val_ids[:3], 'flair')\n",
        "val_loader = DataLoader(val_ds, batch_size=1)\n",
        "\n",
        "global_model = ResNetLite().to(device)\n",
        "global_weights = copy.deepcopy(global_model.state_dict())\n",
        "\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    print(f\"\\n Round {round_num}\")\n",
        "    weights = []\n",
        "\n",
        "    for name, (ids_subset, modality) in clients.items():\n",
        "        print(f\" {name} training on {modality}\")\n",
        "\n",
        "        model = ResNetLite().to(device)\n",
        "        model.load_state_dict(global_weights)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "        ds = BraTSDataset(ids_subset, modality)\n",
        "        dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        privacy_engine = PrivacyEngine()\n",
        "        model, optimizer, dl = privacy_engine.make_private(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=dl,\n",
        "            noise_multiplier=NOISE_MULTIPLIER,\n",
        "            max_grad_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        train_dp(model, dl, optimizer, device)\n",
        "\n",
        "        clean_weights = {k.replace(\"_module.\", \"\"): v for k, v in model.state_dict().items()}\n",
        "        weights.append(clean_weights)\n",
        "\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    new_weights = weights[0]\n",
        "    for k in new_weights:\n",
        "        for i in range(1, len(weights)):\n",
        "            new_weights[k] += weights[i][k]\n",
        "        new_weights[k] /= len(weights)\n",
        "    global_model.load_state_dict(new_weights)\n",
        "\n",
        "    dice = evaluate_model(global_model, val_loader, device)\n",
        "    print(f\" Dice Score: {dice:.4f}\")\n",
        "\n",
        "print(\"\\n FL + DP ResNetLite Training Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM35lk8nkEJR",
        "outputId": "eb3da0e3-1a30-4ea7-c079-1062ee3c08f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Begin FL + DP using ResNetLite\n",
            "\n",
            " Round 1\n",
            " client_1 training on flair\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " client_2 training on t1ce\n",
            " client_3 training on t2\n",
            " Dice Score: 0.6056\n",
            "\n",
            " FL + DP ResNetLite Training Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ε = 8 (epsilon)\n",
        "IMG_SIZE = 64\n",
        "VOLUME_SLICES = 3\n",
        "VOLUME_START_AT = 22\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "ROUNDS = 1\n",
        "LR = 5e-4\n",
        "NOISE_MULTIPLIER = 1.3\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "train_data = \"/content/drive/MyDrive/EECE608/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BraTSDataset(Dataset):\n",
        "    def __init__(self, list_ids, modality):\n",
        "        self.list_ids = list_ids\n",
        "        self.modality = modality\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_ids) * VOLUME_SLICES\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        case_idx = idx // VOLUME_SLICES\n",
        "        slice_idx = VOLUME_START_AT + (idx % VOLUME_SLICES)\n",
        "        case_id = self.list_ids[case_idx]\n",
        "        case_path = os.path.join(train_data, case_id)\n",
        "\n",
        "        img = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_{self.modality}.nii\")).dataobj[:, :, slice_idx], dtype=np.float32)\n",
        "        seg = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_seg.nii\")).dataobj[:, :, slice_idx], dtype=np.uint8)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        seg = cv2.resize(seg, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img / (np.max(img) + 1e-8)\n",
        "        seg[seg == 4] = 3\n",
        "\n",
        "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(seg, dtype=torch.long)\n",
        "\n",
        "class ResNetLite(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), nn.GroupNorm(4, 16), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.GroupNorm(4, 32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.GroupNorm(4, 64), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, 4, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def dice_score(preds, targets, smooth=1e-6):\n",
        "    preds = torch.argmax(preds, dim=1).view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (preds == targets).float().sum()\n",
        "    return (2. * intersection + smooth) / (preds.numel() + targets.numel() + smooth)\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            if out.shape[-2:] != y.shape[-2:]:\n",
        "                out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            score += dice_score(out, y).item()\n",
        "    return score / len(dataloader)\n",
        "def train_dp(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        if out.shape[-2:] != y.shape[-2:]:\n",
        "            out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "def create_clients(ids, modalities=['flair', 't1ce', 't2']):\n",
        "    size = len(ids) // len(modalities)\n",
        "    shards = [ids[i * size:(i + 1) * size] for i in range(len(modalities))]\n",
        "    return {f\"client_{i+1}\": (shards[i], modalities[i]) for i in range(len(modalities))}\n",
        "print(\"\\n Begin FL + DP using ResNetLite\")\n",
        "\n",
        "\n",
        "dirs = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "dirs.remove(train_data + 'BraTS20_Training_355')\n",
        "ids = [os.path.basename(p) for p in dirs]\n",
        "train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "\n",
        "clients = create_clients(train_ids[:6])\n",
        "val_ds = BraTSDataset(val_ids[:3], 'flair')\n",
        "val_loader = DataLoader(val_ds, batch_size=1)\n",
        "\n",
        "global_model = ResNetLite().to(device)\n",
        "global_weights = copy.deepcopy(global_model.state_dict())\n",
        "\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    print(f\"\\n Round {round_num}\")\n",
        "    weights = []\n",
        "\n",
        "    for name, (ids_subset, modality) in clients.items():\n",
        "        print(f\" {name} training on {modality}\")\n",
        "\n",
        "        model = ResNetLite().to(device)\n",
        "        model.load_state_dict(global_weights)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "        ds = BraTSDataset(ids_subset, modality)\n",
        "        dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        privacy_engine = PrivacyEngine()\n",
        "        model, optimizer, dl = privacy_engine.make_private(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=dl,\n",
        "            noise_multiplier=NOISE_MULTIPLIER,\n",
        "            max_grad_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        train_dp(model, dl, optimizer, device)\n",
        "\n",
        "        clean_weights = {k.replace(\"_module.\", \"\"): v for k, v in model.state_dict().items()}\n",
        "        weights.append(clean_weights)\n",
        "\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    new_weights = weights[0]\n",
        "    for k in new_weights:\n",
        "        for i in range(1, len(weights)):\n",
        "            new_weights[k] += weights[i][k]\n",
        "        new_weights[k] /= len(weights)\n",
        "    global_model.load_state_dict(new_weights)\n",
        "\n",
        "    dice = evaluate_model(global_model, val_loader, device)\n",
        "    print(f\" Dice Score: {dice:.4f}\")\n",
        "\n",
        "print(\"\\n FL + DP ResNetLite Training Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbeZrSbHmXDy",
        "outputId": "e0d7228f-4e16-42f2-8eff-5e14e9517ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Begin FL + DP using ResNetLite\n",
            "\n",
            " Round 1\n",
            " client_1 training on flair\n",
            " client_2 training on t1ce\n",
            " client_3 training on t2\n",
            " Dice Score: 0.0497\n",
            "\n",
            " FL + DP ResNetLite Training Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc, copy, cv2\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "\n",
        "IMG_SIZE = 128\n",
        "VOLUME_SLICES = 3\n",
        "VOLUME_START_AT = 22\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "ROUNDS = 1\n",
        "LR = 5e-4\n",
        "NOISE_MULTIPLIER = 1.3\n",
        "MAX_GRAD_NORM = 1.0\n",
        "NUM_CLASSES = 4\n",
        "train_data = \"/content/drive/MyDrive/EECE608/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BraTSDataset(Dataset):\n",
        "    def __init__(self, list_ids, modality):\n",
        "        self.list_ids = list_ids\n",
        "        self.modality = modality\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_ids) * VOLUME_SLICES\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        case_idx = idx // VOLUME_SLICES\n",
        "        slice_idx = VOLUME_START_AT + (idx % VOLUME_SLICES)\n",
        "        case_id = self.list_ids[case_idx]\n",
        "        case_path = os.path.join(train_data, case_id)\n",
        "\n",
        "        img = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_{self.modality}.nii\")).dataobj[:, :, slice_idx], dtype=np.float32)\n",
        "        seg = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_seg.nii\")).dataobj[:, :, slice_idx], dtype=np.uint8)\n",
        "\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        seg = cv2.resize(seg, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img / (np.max(img) + 1e-8)\n",
        "        seg[seg == 4] = 3\n",
        "\n",
        "        return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(seg, dtype=torch.long)\n",
        "\n",
        "def convert_batchnorm_to_groupnorm(model):\n",
        "    model = ModuleValidator.fix(model)\n",
        "    return model\n",
        "\n",
        "def get_deeplab():\n",
        "    model = models.segmentation.deeplabv3_resnet50(weights=None, num_classes=NUM_CLASSES)\n",
        "    # Modify first conv layer: 3 ➜ 1 input channel\n",
        "    old_conv = model.backbone.conv1\n",
        "    model.backbone.conv1 = nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=old_conv.out_channels,\n",
        "        kernel_size=old_conv.kernel_size,\n",
        "        stride=old_conv.stride,\n",
        "        padding=old_conv.padding,\n",
        "        bias=old_conv.bias is not None\n",
        "    )\n",
        "    model = convert_batchnorm_to_groupnorm(model)\n",
        "    return model\n",
        "\n",
        "def dice_score(preds, targets, smooth=1e-6):\n",
        "    preds = torch.argmax(preds, dim=1).view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (preds == targets).float().sum()\n",
        "    return (2. * intersection + smooth) / (preds.numel() + targets.numel() + smooth)\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    score = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)['out']\n",
        "            if out.shape[-2:] != y.shape[-2:]:\n",
        "                out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            score += dice_score(out, y).item()\n",
        "    return score / len(dataloader)\n",
        "\n",
        "def train_dp(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)['out']\n",
        "        if out.shape[-2:] != y.shape[-2:]:\n",
        "            out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def create_clients(ids, modalities=['flair', 't1ce', 't2']):\n",
        "    size = len(ids) // len(modalities)\n",
        "    shards = [ids[i * size:(i + 1) * size] for i in range(len(modalities))]\n",
        "    return {f\"client_{i+1}\": (shards[i], modalities[i]) for i in range(len(modalities))}\n",
        "\n",
        "print(\"\\n FL + DP with DeepLabV3\")\n",
        "\n",
        "dirs = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "dirs.remove(train_data + 'BraTS20_Training_355')\n",
        "ids = [os.path.basename(p) for p in dirs]\n",
        "train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "\n",
        "clients = create_clients(train_ids[:6])\n",
        "val_ds = BraTSDataset(val_ids[:3], 'flair')\n",
        "val_loader = DataLoader(val_ds, batch_size=1)\n",
        "\n",
        "global_model = get_deeplab().to(device)\n",
        "global_weights = copy.deepcopy(global_model.state_dict())\n",
        "\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    print(f\"\\n Round {round_num}\")\n",
        "    weights = []\n",
        "\n",
        "    for name, (ids_subset, modality) in clients.items():\n",
        "        print(f\" {name} training on {modality}\")\n",
        "        model = get_deeplab().to(device)\n",
        "        model.load_state_dict(global_weights)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "        ds = BraTSDataset(ids_subset, modality)\n",
        "        dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "        privacy_engine = PrivacyEngine()\n",
        "        model, optimizer, dl = privacy_engine.make_private(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=dl,\n",
        "            noise_multiplier=NOISE_MULTIPLIER,\n",
        "            max_grad_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        train_dp(model, dl, optimizer, device)\n",
        "\n",
        "        clean_weights = {k.replace(\"_module.\", \"\"): v for k, v in model.state_dict().items()}\n",
        "        weights.append(clean_weights)\n",
        "\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    new_weights = weights[0]\n",
        "    for k in new_weights:\n",
        "        for i in range(1, len(weights)):\n",
        "            new_weights[k] += weights[i][k]\n",
        "        new_weights[k] /= len(weights)\n",
        "    global_model.load_state_dict(new_weights)\n",
        "\n",
        "    dice = evaluate_model(global_model, val_loader, device)\n",
        "    print(f\" Dice Score: {dice:.4f}\")\n",
        "\n",
        "print(\"\\n Training Complete — DeepLabV3 + DP + FL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZv_NlHrnpc5",
        "outputId": "090f52c9-c91f-4c50-e9c1-5c100fe1b51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FL + DP with DeepLabV3\n",
            "\n",
            " Round 1\n",
            " client_1 training on flair\n",
            " client_2 training on t1ce\n",
            " client_3 training on t2\n",
            " Dice Score: 0.4710\n",
            "\n",
            " Training Complete — DeepLabV3 + DP + FL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMG_SIZE = 128\n",
        "# VOLUME_SLICES = 3\n",
        "# VOLUME_START_AT = 22\n",
        "# BATCH_SIZE = 1\n",
        "# EPOCHS = 1\n",
        "# ROUNDS = 1\n",
        "# LR = 5e-4\n",
        "# NOISE_MULTIPLIER = 1.3\n",
        "# MAX_GRAD_NORM = 1.0\n",
        "# NUM_CLASSES = 4\n",
        "# train_data = \"/content/drive/MyDrive/EECE608/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# class BraTSDataset(Dataset):\n",
        "#     def __init__(self, list_ids, modality):\n",
        "#         self.list_ids = list_ids\n",
        "#         self.modality = modality\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.list_ids) * VOLUME_SLICES\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         case_idx = idx // VOLUME_SLICES\n",
        "#         slice_idx = VOLUME_START_AT + (idx % VOLUME_SLICES)\n",
        "#         case_id = self.list_ids[case_idx]\n",
        "#         case_path = os.path.join(train_data, case_id)\n",
        "\n",
        "#         img = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_{self.modality}.nii\")).dataobj[:, :, slice_idx], dtype=np.float32)\n",
        "#         seg = np.asarray(nib.load(os.path.join(case_path, f\"{case_id}_seg.nii\")).dataobj[:, :, slice_idx], dtype=np.uint8)\n",
        "\n",
        "#         img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "#         seg = cv2.resize(seg, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#         img = img / (np.max(img) + 1e-8)\n",
        "#         seg[seg == 4] = 3\n",
        "\n",
        "#         return torch.tensor(img, dtype=torch.float32).unsqueeze(0), torch.tensor(seg, dtype=torch.long)\n",
        "\n",
        "# def convert_batchnorm_to_groupnorm(model):\n",
        "#     model = ModuleValidator.fix(model)\n",
        "#     return model\n",
        "\n",
        "# def get_deeplab():\n",
        "#     model = models.segmentation.deeplabv3_resnet50(weights=None, num_classes=NUM_CLASSES)\n",
        "#     # Modify first conv layer: 3 ➜ 1 input channel\n",
        "#     old_conv = model.backbone.conv1\n",
        "#     model.backbone.conv1 = nn.Conv2d(\n",
        "#         in_channels=1,\n",
        "#         out_channels=old_conv.out_channels,\n",
        "#         kernel_size=old_conv.kernel_size,\n",
        "#         stride=old_conv.stride,\n",
        "#         padding=old_conv.padding,\n",
        "#         bias=old_conv.bias is not None\n",
        "#     )\n",
        "#     model = convert_batchnorm_to_groupnorm(model)\n",
        "#     return model\n",
        "\n",
        "# def dice_score(preds, targets, smooth=1e-6):\n",
        "#     preds = torch.argmax(preds, dim=1).view(-1)\n",
        "#     targets = targets.view(-1)\n",
        "#     intersection = (preds == targets).float().sum()\n",
        "#     return (2. * intersection + smooth) / (preds.numel() + targets.numel() + smooth)\n",
        "\n",
        "\n",
        "# def evaluate_model(model, dataloader, device):\n",
        "#     model.eval()\n",
        "#     score = 0\n",
        "#     with torch.no_grad():\n",
        "#         for x, y in dataloader:\n",
        "#             x, y = x.to(device), y.to(device)\n",
        "#             out = model(x)['out']\n",
        "#             if out.shape[-2:] != y.shape[-2:]:\n",
        "#                 out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "#             score += dice_score(out, y).item()\n",
        "#     return score / len(dataloader)\n",
        "\n",
        "# def train_dp(model, dataloader, optimizer, device):\n",
        "#     model.train()\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     for x, y in dataloader:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(x)['out']\n",
        "#         if out.shape[-2:] != y.shape[-2:]:\n",
        "#             out = F.interpolate(out, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
        "#         loss = criterion(out, y)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# def create_clients(ids, modalities=['flair', 't1ce', 't2']):\n",
        "#     size = len(ids) // len(modalities)\n",
        "#     shards = [ids[i * size:(i + 1) * size] for i in range(len(modalities))]\n",
        "#     return {f\"client_{i+1}\": (shards[i], modalities[i]) for i in range(len(modalities))}\n",
        "\n",
        "# print(\"\\n FL + DP with DeepLabV3\")\n",
        "\n",
        "# dirs = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "# dirs.remove(train_data + 'BraTS20_Training_355')\n",
        "# ids = [os.path.basename(p) for p in dirs]\n",
        "# train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "\n",
        "# clients = create_clients(train_ids[:6])\n",
        "# val_ds = BraTSDataset(val_ids[:3], 'flair')\n",
        "# val_loader = DataLoader(val_ds, batch_size=1)\n",
        "\n",
        "# global_model = get_deeplab().to(device)\n",
        "# global_weights = copy.deepcopy(global_model.state_dict())\n",
        "\n",
        "# for round_num in range(1, ROUNDS + 1):\n",
        "#     print(f\"\\n Round {round_num}\")\n",
        "#     weights = []\n",
        "\n",
        "#     for name, (ids_subset, modality) in clients.items():\n",
        "#         print(f\" {name} training on {modality}\")\n",
        "#         model = get_deeplab().to(device)\n",
        "#         model.load_state_dict(global_weights)\n",
        "#         optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "#         ds = BraTSDataset(ids_subset, modality)\n",
        "#         dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "#         privacy_engine = PrivacyEngine()\n",
        "#         model, optimizer, dl = privacy_engine.make_private(\n",
        "#             module=model,\n",
        "#             optimizer=optimizer,\n",
        "#             data_loader=dl,\n",
        "#             noise_multiplier=NOISE_MULTIPLIER,\n",
        "#             max_grad_norm=MAX_GRAD_NORM\n",
        "#         )\n",
        "\n",
        "#         train_dp(model, dl, optimizer, device)\n",
        "\n",
        "#         clean_weights = {k.replace(\"_module.\", \"\"): v for k, v in model.state_dict().items()}\n",
        "#         weights.append(clean_weights)\n",
        "\n",
        "#         del model, optimizer\n",
        "#         torch.cuda.empty_cache()\n",
        "#         gc.collect()\n",
        "\n",
        "#     new_weights = weights[0]\n",
        "#     for k in new_weights:\n",
        "#         for i in range(1, len(weights)):\n",
        "#             new_weights[k] += weights[i][k]\n",
        "#         new_weights[k] /= len(weights)\n",
        "#     global_model.load_state_dict(new_weights)\n",
        "\n",
        "#     dice = evaluate_model(global_model, val_loader, device)\n",
        "#     print(f\" Dice Score: {dice:.4f}\")\n",
        "\n",
        "# print(\"\\n Training Complete — DeepLabV3 + DP + FL\")"
      ],
      "metadata": {
        "id": "adh8hFr4oJSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}